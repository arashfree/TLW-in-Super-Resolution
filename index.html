
<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">

  <head>
    <meta name="google-site-verification" content="-BQHtZum5Vme9zxJcJ2LolF5EVQjGuxpwg2RPGJQBW8" />

    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
          <h1 id="project_title">Trainable Loss Weights in Super-Resolution </h1>
          <h2 id="project_tagline">Arash Chaichi Mellatshahi, Shohreh Kasaei </h2>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        In recent years, limited research has discussed the loss function in the super-resolution process. The majority of those studies have only used perceptual similarity conventionally. This is while the development of appropriate loss can improve the quality of other methods as well. In this article, a new weighting method for pixel-wise loss is proposed. With the help of this method, it is possible to use trainable weights based on the general structure of the image and its perceptual features while maintaining the advantages of pixel-wise loss. Also, a criterion for comparing weights of loss is introduced so that the weights can be estimated directly by a convolutional neural network. In addition, in this article, the expectation-maximization method is used for the simultaneous estimation super-resolution network and weighting network. In addition, a new activation function, called “FixedSum”, is introduced which can keep the sum of all components of vector constants while keeping the output components between zero and one. As experimental results shows, weighted loss by the proposed method leads to better results than the unweighted loss and weighted loss based on uncertainty in both signal-to-noise and perceptual similarity senses on the state-of-the-art networks. Code is available online.
      </section>
      <section id="downloads">
        <a id="forkme_banner" href="https://github.com/arashfree/TLW-in-Super-Resolution/tree/main">GitHub</a>
    
        <a href="https://arxiv.org/abs/2301.10575">Paper</a>
        <a href="https://github.com/arashfree/TLW-in-Super-Resolution/archive/refs/heads/main.zip">Download</a>
        <a href="git@github.com:arashfree/TLW-in-Super-Resolution.git">Clone</a>
      </section>

    </div>

    <!-- FOOTER  -->
    
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        {% if site.github.is_project_page %}
        
        <p class="copyright">{{ site.title | default: site.github.repository_name }} maintained by <a href="{{ site.github.owner_url }}">{{ site.github.owner_name }}</a></p>
        {% endif %}
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
        <p>article{ 
          mellatshahi2023trainable, 
          title={Trainable Loss Weights in Super-Resolution}, 
          author={Mellatshahi Chaichi, Arash and Kasaei, Shohreh},   
          journal={arXiv preprint arXiv:2301.10575},
          year={2023} 
        }</p>
      </footer>
    </div>
  </body>
</html>
